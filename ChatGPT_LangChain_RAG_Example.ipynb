{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYyaYe8md8a0UgqA82PslC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takiguchi-yu/google-colab/blob/main/ChatGPT_LangChain_RAG_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 参考資料\n",
        "\n",
        "https://qiita.com/hiroki_okuhata_int/items/5dc6149ded35c5c3a40f"
      ],
      "metadata": {
        "id": "6HDgP5pJ6f9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colab での Python コードの実行"
      ],
      "metadata": {
        "id": "-OpZoaoc9N9l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozjp5y5yuAGW",
        "outputId": "410fabe5-80ec-418d-e629-76fd894deee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "openai\n",
        "chromadb\n",
        "langchain\n",
        "deeplake\n",
        "tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "UcPq78062O46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "import openai\n",
        "import langchain\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.vectorstores import DeepLake"
      ],
      "metadata": {
        "id": "sTsmPpyu2TSY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 解析したいソースコードの読み込み"
      ],
      "metadata": {
        "id": "X4SqA37l9Yeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/takiguchi-yu/cognito-google-federation-example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ThHUY784_1j",
        "outputId": "321e879e-f244-46e7-d4fb-1d0125f9de65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cognito-google-federation-example'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 147 (delta 40), reused 145 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (147/147), 1.02 MiB | 17.65 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = './cognito-google-federation-example'\n",
        "docs = []\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for file in filenames:\n",
        "        try:\n",
        "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "            docs.extend(loader.load_and_split())\n",
        "        except Exception as e:\n",
        "            pass\n"
      ],
      "metadata": {
        "id": "55olEBl55k_P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 上記で読み込んだ、docs 配列の２番目の要素を見てみましょう。\n",
        "docs[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC0OAXLv6Z2-",
        "outputId": "c391c217-b976-412e-82b2-77939b9c0417"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='{\\n  \"recommendations\": [\"esbenp.prettier-vscode\", \"editorconfig.editorconfig\", \"dbaeumer.vscode-eslint\", \"eamodio.gitlens\", \"hediet.vscode-drawio\"]\\n}', metadata={'source': './cognito-google-federation-example/.vscode/extensions.json'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ソースコードの内容を分割する"
      ],
      "metadata": {
        "id": "NofCmTF39dAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "# 実行すると WARNING が出ることがあります。\n",
        "# ソースコードテキストは、必ずしも指定したサイズごとにきれいに区切れるとは限らないため、下記のような警告がでることがあるます。\n",
        "# 概ね ChatGPT のモデルで扱えるサイズに収まっているため、ここでは無視することとします。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hWr9PqX6a-D",
        "outputId": "051cbaa6-f296-43fe-9481-1f268f08526a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1501, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1020, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1540, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割されたテキストの一つを見てみると、小さいチャンクに区切られていることが確認できます。\n",
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG0I1fSJ8XPY",
        "outputId": "bc31c566-b83c-450e-820d-c7402c772f56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='## Overview', metadata={'source': './cognito-google-federation-example/README.md'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain における LLM のセットアップ"
      ],
      "metadata": {
        "id": "HdOqQeRX9h33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "# llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4')"
      ],
      "metadata": {
        "id": "7iag6QCN8fcw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分割したテキストの情報をベクターストアに格納する\n",
        "次に、分割したテキストについて、テキスト間の関連性に関するベクターデータをベクターストアに格納します。\n",
        "\n",
        "本記事では、ChatGPT に与えるベクターストアとして、DeepLake という Deep Learning 用のデータレイクサービスを使用します。\n",
        "\n",
        "DeepLake とは\n",
        "https://python.langchain.com/docs/integrations/vectorstores/activeloop_deeplake"
      ],
      "metadata": {
        "id": "CrhGgbfc-6ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['ACTIVELOOP_TOKEN'] = 'eyJhbGciOiJIUzUxMiIsImlhdCI6MTcwNTcyMzExNSwiZXhwIjoxNzM3MzQ1NDk5fQ.eyJpZCI6InRha2lndWNoaXl1In0.i5UAxTFyoLWkGkZ9dpZziVFhEkMUjVsUPJuLIUP3wjPgGIj3kJlL_6L54-XnYIwwb-bKreSq3BkcFr_FhQjimg'\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "dataset_path = \"hub://takiguchiyu/ChatGPT-LangChain-RAG-Example\"\n",
        "\n",
        "# db = DeepLake.from_documents(texts, embeddings, dataset_path=dataset_path, read_only=True)\n",
        "db = DeepLake.from_documents(texts, embeddings, dataset_path=dataset_path, read_only=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frgYGvBG--DY",
        "outputId": "91df12c4-9698-4eb6-c2f4-dfe331d5840c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Lake Dataset in hub://takiguchiyu/ChatGPT-LangChain-RAG-Example already exists, loading from the storage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating 175 embeddings in 1 batches of size 175:: 100%|██████████| 1/1 [00:35<00:00, 35.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://takiguchiyu/ChatGPT-LangChain-RAG-Example', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype       shape      dtype  compression\n",
            "  -------    -------     -------    -------  ------- \n",
            " embedding  embedding  (350, 1536)  float32   None   \n",
            "    id        text      (350, 1)      str     None   \n",
            " metadata     json      (350, 1)      str     None   \n",
            "   text       text      (350, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# このベクターストアを下記のように LLM に与えることで、テキスト間の関連性について表現したベクトルデータを LLM に使用させることをできます。\n",
        "retriever = db.as_retriever()\n",
        "retriever.search_kwargs['distance_metric'] = 'cos'\n",
        "retriever.search_kwargs['fetch_k'] = 100\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 20\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever)"
      ],
      "metadata": {
        "id": "Vi3W5TXbe1h5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ソースコードの内容を自然言語で問い合わせる"
      ],
      "metadata": {
        "id": "vJZT57uTym7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "questions = [\n",
        "    \"cognito-google-federation-exampleについて教えてください\",\n",
        "    \"全体の処理フローを mermaid 形式で書いてください。\",\n",
        "    # \"Lambda の Login では何をやっていますか。\",\n",
        "    # \"OAuth2認証の検索パラメータを教えてください。\",\n",
        "]\n",
        "chat_history = []\n",
        "\n",
        "for question in questions:\n",
        "  result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "  chat_history.append((question, result['answer']))\n",
        "  print(f\"-> **Question** : {question} \\n\")\n",
        "  print(f\"-> **Answer** : {result['answer']} \\n\")\n",
        "  # time.sleep(25) # 無料プランの場合はAPIコール数に制限があるので sleep させる。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncCCsKEqyqU1",
        "outputId": "9ad7c8fb-e5bd-4272-8084-8693772558a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> **Question** : cognito-google-federation-exampleについて教えてください \n",
            "\n",
            "-> **Answer** : \"cognito-google-federation-example\"は、Amazon CognitoとGoogleの認証を連携させるための実装例です。このプロジェクトでは、フロントエンドとバックエンドの両方でTypeScriptが使用されています。フロントエンドではReactとTailwind CSSを使用し、バックエンドではNode.jsが使用されています。また、AWSのインフラストラクチャとして使用されています。\n",
            "\n",
            "具体的には、Google Cloud Platformで新しいプロジェクトを作成し、OAuth同意画面と認証情報を設定します。その後、AWSの環境を構築し、Googleの認証情報を使用してCognitoユーザープールを作成します。これにより、ユーザーはGoogleの認証情報を使用してアプリケーションにサインインできます。\n",
            "\n",
            "また、このプロジェクトでは、API GatewayとLambdaを使用してバックエンドAPIを作成し、パラメータストアを使用して設定情報を管理しています。 \n",
            "\n",
            "-> **Question** : 全体の処理フローを mermaid 形式で書いてください。 \n",
            "\n",
            "-> **Answer** : ```mermaid\n",
            "sequenceDiagram\n",
            "    participant Frontend\n",
            "    participant Backend\n",
            "    participant Cognito\n",
            "    participant Google\n",
            "    Frontend->>Backend: /auth/login<br>Request unique login URL (Cognito Hosted UI)\n",
            "    Backend->>Cognito: /oauth2/authorize<br>Request unique login URL (Cognito Hosted UI)\n",
            "    Cognito->>Backend: Return unique login URL (Cognito Hosted UI)\n",
            "    Backend->>Frontend: Return unique login URL (Cognito Hosted UI)\n",
            "    Frontend->>Cognito: Redirect to login URL (Cognito Hosted UI)\n",
            "    Cognito->>Cognito: Check internally if user already authenticated with Google account recently\n",
            "    Cognito->>Google: If authorization expired or never happened,<br/> redirect to Google Hosted UI for authorization.<br/>User enters Google credentials and approves Cognito to read his Google email.\n",
            "    Google->>Cognito: Internal redirect. <br/>Provisions the Google user to Cognito User Pool and map fields like \"email\" to Cognito user fields\n",
            "    Cognito->>Frontend: Redirect with one-time AuthorizationCode in query parameter\n",
            "    Frontend->>Backend: /auth/token & /user<br />Pass one-time AuthorizationCode<br/>Request long lived credentials (IdToken, AccessToken, RefreshToken)\n",
            "    Backend->>Cognito: Exchange AuthorizationCode for long lived credentials\n",
            "    Backend->>Frontend: Return long lived credentials\n",
            "    Frontend->>Frontend: Store long lived credentials<br/>(Cookie, LocalStorage, IndexedDB, etc)\n",
            "    Frontend->>Backend: Make calls to authenticated resources using long lived credentials\n",
            "```\n",
            "このダイアグラムは、フロントエンドがバックエンドにログインURLを要求し、バックエンドがCognitoにそれを要求するところから始まります。CognitoはバックエンドにURLを返し、バックエンドはフロントエンドにそれを返します。その後、フロントエンドはCognitoのログインURLにリダイレクトします。Cognitoは内部でユーザーが最近Googleアカウントで認証されたかどうかを確認します。認証が期限切れまたは未実施の場合、CognitoはGoogleのホストUIにリダイレクトして認証を求めます。ユーザーはGoogleの資格情報を入力し、CognitoがGoogleのメールを読むことを承認します。GoogleはCognitoに内部リダイレクトを行い、GoogleユーザーをCognitoユーザープールに提供し、\"email\"のようなフィールドをCognitoユーザーフィールドにマップします。Cognitoは一回限りのAuthorizationCodeをクエリパラメータに含めてフロントエンドにリダイレクトします。フロントエンドは一回限りのAuthorizationCodeを渡し、長期的な資格情報（IdToken、AccessToken、RefreshToken）を要求します。バックエンドはAuthorizationCodeを長期的な資格情報と交換し、フロントエンドにそれを返します。フロントエンドは長期的な資格情報を保存し（Cookie、LocalStorage、IndexedDBなど）、長期的な資格情報を使用して認証済みリソースへの呼び出しを行います。 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}